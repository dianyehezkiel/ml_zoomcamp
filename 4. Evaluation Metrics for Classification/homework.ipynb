{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Homework 4"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data:\n",
    "\n",
    "- https://github.com/gastonstat/CreditScoring\n",
    "- Also available [here](https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-06-trees/CreditScoring.csv)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-06-trees/CreditScoring.csv -O data.csv"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2021-10-04 21:05:47--  https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-06-trees/CreditScoring.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 182489 (178K) [text/plain]\n",
      "Saving to: ‘data.csv’\n",
      "\n",
      "data.csv            100%[===================>] 178,21K  --.-KB/s    in 0,1s    \n",
      "\n",
      "2021-10-04 21:05:47 (1,51 MB/s) - ‘data.csv’ saved [182489/182489]\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparation \n",
    "\n",
    "We'll talk about this dataset in more details in week 6. But for now, use the following code to get started"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.columns = df.columns.str.lower()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some of the features are encoded as numbers. Use the following code to de-code them:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "status_values = {\n",
    "    1: 'ok',\n",
    "    2: 'default',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.status = df.status.map(status_values)\n",
    "\n",
    "\n",
    "home_values = {\n",
    "    1: 'rent',\n",
    "    2: 'owner',\n",
    "    3: 'private',\n",
    "    4: 'ignore',\n",
    "    5: 'parents',\n",
    "    6: 'other',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.home = df.home.map(home_values)\n",
    "\n",
    "marital_values = {\n",
    "    1: 'single',\n",
    "    2: 'married',\n",
    "    3: 'widow',\n",
    "    4: 'separated',\n",
    "    5: 'divorced',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.marital = df.marital.map(marital_values)\n",
    "\n",
    "records_values = {\n",
    "    1: 'no',\n",
    "    2: 'yes',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.records = df.records.map(records_values)\n",
    "\n",
    "job_values = {\n",
    "    1: 'fixed',\n",
    "    2: 'partime',\n",
    "    3: 'freelance',\n",
    "    4: 'others',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.job = df.job.map(job_values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prepare the numerical variables:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "for c in ['income', 'assets', 'debt']:\n",
    "    df[c] = df[c].replace(to_replace=99999999, value=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove clients with unknown default status"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df = df[df.status != 'unk'].reset_index(drop=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the target variable"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df['default'] = (df.status == 'default').astype(int)\n",
    "del df['status']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Your code"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "What are the categorical variables? What are the numerical?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "numerical = [\n",
    "    'seniority',\n",
    "    'time',\n",
    "    'age',\n",
    "    'expenses',\n",
    "    'income',\n",
    "    'assets',\n",
    "    'debt',\n",
    "    'amount',\n",
    "    'price'\n",
    "    ]\n",
    "\n",
    "categorical = [\n",
    "    'home',\n",
    "    'marital',\n",
    "    'records',\n",
    "    'job',\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split the data into 3 parts: train/validation/test with 60%/20%/20% distribution. Use `train_test_split` funciton for that with `random_state=1`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 1\n",
    "\n",
    "ROC AUC could also be used to evaluate feature importance of numerical variables. \n",
    "\n",
    "Let's do that\n",
    "\n",
    "* For each numerical variable, use it as score and compute AUC with the \"default\" variable\n",
    "* Use the training dataset for that\n",
    "\n",
    "\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
    "\n",
    "(e.g. `-df_train['expenses']`)\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target varialble. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "for n_var in numerical:\n",
    "    score = roc_auc_score(df_train['default'], df_train[n_var])\n",
    "    if (score<0.5):\n",
    "        print(n_var, '(negative)')\n",
    "        score = roc_auc_score(df_train['default'], -df_train[n_var])\n",
    "    else:\n",
    "        print(n_var)\n",
    "    \n",
    "    print(score)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "seniority (negative)\n",
      "0.7093778624491943\n",
      "time\n",
      "0.5608662489595051\n",
      "age (negative)\n",
      "0.5732933272499939\n",
      "expenses (negative)\n",
      "0.5009184217217011\n",
      "income (negative)\n",
      "0.682006666132633\n",
      "assets (negative)\n",
      "0.6486042567122802\n",
      "debt (negative)\n",
      "0.5047829675783548\n",
      "amount\n",
      "0.5910773431595518\n",
      "price\n",
      "0.5043329862114843\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Which numerical variable (among the following 4) has the highest AUC?\n",
    "\n",
    "- **seniority**\n",
    "- time\n",
    "- income\n",
    "- debt"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the model\n",
    "\n",
    "From now on, use these columns only:\n",
    "\n",
    "```\n",
    "['seniority', 'income', 'assets', 'records', 'job', 'home']\n",
    "```\n",
    "\n",
    "Apply one-hot-encoding using `DictVectorizer` and train the logistic regression with these parameters:\n",
    "\n",
    "```\n",
    "LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "df_feature = ['seniority', 'income', 'assets', 'records', 'job', 'home']\n",
    "\n",
    "df_train_n = df_train[df_feature]\n",
    "df_val_n = df_val[df_feature]\n",
    "df_test_n = df_test[df_feature]\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "dict_train = df_train_n.to_dict(orient='records')\n",
    "dict_val = df_val_n.to_dict(orient='records')\n",
    "dict_test = df_test_n.to_dict(orient='records')\n",
    "\n",
    "X_train = dv.fit_transform(dict_train)\n",
    "X_val = dv.fit_transform(dict_val)\n",
    "X_test = dv.fit_transform(dict_test)\n",
    "\n",
    "y_train = df_train.default.values\n",
    "y_val = df_val.default.values\n",
    "y_test = df_test.default.values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "lr = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(round(roc_auc_score(y_val, y_pred), 3))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.812\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 2\n",
    "\n",
    "What's the AUC of this model on the validation dataset? (round to 3 digits)\n",
    "\n",
    "- 0.512\n",
    "- 0.612\n",
    "- 0.712\n",
    "- **0.812**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 3\n",
    "\n",
    "Now let's compute precision and recall for our model.\n",
    "\n",
    "* Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01\n",
    "* For each threshold, compute precision and recall\n",
    "* Plot them"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "scores = []\n",
    "thresholds = np.linspace(0, 1, 101)\n",
    "y_pred_proba = lr.predict_proba(X_val)[:, 1]\n",
    "\n",
    "for t in thresholds:\n",
    "    actual_positive = (y_val == 1)\n",
    "    actual_negative = (y_val == 0)\n",
    "\n",
    "    predict_positive = (y_pred_proba >= t)\n",
    "    predict_negative = (y_pred_proba < t)\n",
    "\n",
    "    tp = (predict_positive & actual_positive).sum()\n",
    "    tn = (predict_negative & actual_negative).sum()\n",
    "\n",
    "    fp = (predict_positive & actual_negative).sum()\n",
    "    fn = (predict_negative & actual_positive).sum()\n",
    "    scores.append((t, tp, fp, fn, tn))\n",
    "\n",
    "columns = ['threshold', 'tp', 'fp', 'fn', 'tn']\n",
    "df_scores = pd.DataFrame(scores, columns=columns)\n",
    "\n",
    "df_scores['tpr'] = df_scores.tp / (df_scores.tp + df_scores.fn)\n",
    "df_scores['fpr'] = df_scores.fp / (df_scores.fp + df_scores.tn)\n",
    "\n",
    "plt.plot(df_scores.threshold, df_scores['tpr'], label='TPR')\n",
    "plt.plot(df_scores.threshold, df_scores['fpr'], label='FPR')\n",
    "plt.legend()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc58a0e7e20>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "print(df_scores[df_scores['tpr'] == df_scores['fpr']])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     threshold   tp   fp   fn   tn  tpr  fpr\n",
      "0         0.00  246  645    0    0  1.0  1.0\n",
      "94        0.94    0    0  246  645  0.0  0.0\n",
      "95        0.95    0    0  246  645  0.0  0.0\n",
      "96        0.96    0    0  246  645  0.0  0.0\n",
      "97        0.97    0    0  246  645  0.0  0.0\n",
      "98        0.98    0    0  246  645  0.0  0.0\n",
      "99        0.99    0    0  246  645  0.0  0.0\n",
      "100       1.00    0    0  246  645  0.0  0.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "At which threshold precision and recall curves intersect?\n",
    "\n",
    "* 0.2\n",
    "* 0.4\n",
    "* 0.6\n",
    "* **0.8**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 4\n",
    "\n",
    "Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n",
    "\n",
    "This is the formula for computing F1:\n",
    "\n",
    "$$F_1 = 2 \\cdot \\cfrac{P \\cdot R}{P + R}$$\n",
    "\n",
    "Where $P$ is precision and $R$ is recall.\n",
    "\n",
    "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "f1_score = []\n",
    "\n",
    "for i, r in df_scores.iterrows():\n",
    "    precision = r.tp / (r.tp + r.fp)\n",
    "    recall = r.tp / (r.tp + r.fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    f1_score.append(f1)\n",
    "\n",
    "df_scores['f1'] = f1_score\n",
    "df_scores[df_scores['f1'] == df_scores['f1'].max()]\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipykernel_8684/3736754614.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  precision = r.tp / (r.tp + r.fp)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.3</td>\n",
       "      <td>187</td>\n",
       "      <td>162</td>\n",
       "      <td>59</td>\n",
       "      <td>483</td>\n",
       "      <td>0.760163</td>\n",
       "      <td>0.251163</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold   tp   fp  fn   tn       tpr       fpr        f1\n",
       "30        0.3  187  162  59  483  0.760163  0.251163  0.628571"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "At which threshold F1 is maximal?\n",
    "\n",
    "- 0.1\n",
    "- **0.3**\n",
    "- 0.5\n",
    "- 0.7"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 5\n",
    "\n",
    "\n",
    "Use the `KFold` class from Scikit-Learn to evaluate our model on 5 different folds:\n",
    "\n",
    "```\n",
    "KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "```\n",
    "\n",
    "* Iterate over different folds of `df_full_train`\n",
    "* Split the data into train and validation\n",
    "* Train the model on train with these parameters: `LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)`\n",
    "* Use AUC to evaluate the model on validation\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def train(df_train, y_train, C=1.0):\n",
    "    dicts = df_train[df_feature].to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return dv, model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def predict(df, dv, model):\n",
    "    dicts = df[df_feature].to_dict(orient='records')\n",
    "\n",
    "    X = dv.transform(dicts)\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return y_pred"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "scores = []\n",
    "for train_idx, val_idx in kfold.split(df_full_train):\n",
    "    df_train_f = df_full_train.iloc[train_idx]\n",
    "    df_val_f = df_full_train.iloc[val_idx]\n",
    "\n",
    "    y_train = df_train_f.default.values\n",
    "    y_val = df_val_f.default.values\n",
    "\n",
    "    dv, model = train(df_train_f, y_train, 1)\n",
    "    y_pred = predict(df_val_f, dv, model)\n",
    "\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    scores.append(auc)\n",
    "\n",
    "print(round(np.std(scores), 3))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.014\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "How large is standard devidation of the scores across different folds?\n",
    "\n",
    "- 0.001\n",
    "- **0.014**\n",
    "- 0.09\n",
    "- 0.14"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 6\n",
    "\n",
    "Now let's use 5-Fold cross-validation to find the best parameter C\n",
    "\n",
    "* Iterate over the following C values: `[0.01, 0.1, 1, 10]`\n",
    "* Initialize `KFold` with the same parameters as previously\n",
    "* Use these parametes for the model: `LogisticRegression(solver='liblinear', C=C, max_iter=1000)`\n",
    "* Compute the mean score as well as the std (round the mean and std to 3 decimal digits)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "C = [0.01, 0.1, 1, 10]\n",
    "\n",
    "for c in C:\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    scores = []\n",
    "    for train_idx, val_idx in kfold.split(df_full_train):\n",
    "        df_train_f = df_full_train.iloc[train_idx]\n",
    "        df_val_f = df_full_train.iloc[val_idx]\n",
    "\n",
    "        y_train = df_train_f.default.values\n",
    "        y_val = df_val_f.default.values\n",
    "\n",
    "        dv, model = train(df_train_f, y_train, c)\n",
    "        y_pred = predict(df_val_f, dv, model)\n",
    "\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        scores.append(auc)\n",
    "\n",
    "    print('C=%s %.3f +- %.3f' % (c, np.mean(scores), np.std(scores)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "C=0.01 0.809 +- 0.013\n",
      "C=0.1 0.813 +- 0.014\n",
      "C=1 0.812 +- 0.014\n",
      "C=10 0.814 +- 0.015\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Which C leads to the best mean score?\n",
    "\n",
    "- 0.01\n",
    "- 0.1\n",
    "- 1\n",
    "- **10**\n",
    "\n",
    "If you have ties, select the score with the lowest std. If you still have ties, select the smallest C"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('learn_env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "9bb974fa0cc6142a59afcfb9c207eab639d0b62b05239eae56738e28e4683771"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}